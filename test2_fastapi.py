"""
ğŸ“Œ ë¹„ìƒ ì •ì§€ ì‹œìŠ¤í…œ (ì† ê°ì§€ ê¸°ë°˜)
- MediaPipeë¥¼ ì´ìš©í•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì†ì„ ê°ì§€í•˜ê³ 
- ROI ì•ˆì— ì†ì´ ë“¤ì–´ì˜¤ë©´ Mitsubishi PLC(D8)ì— ë¹„ìƒì •ì§€ ì‹ í˜¸ë¥¼ ì „ë‹¬
- FastAPIë¡œ ì›¹ì—ì„œ ì‹¤ì‹œê°„ ì˜ìƒ í™•ì¸ ê°€ëŠ¥
"""

import cv2
import time
import threading
import uvicorn
import pymcprotocol as mc
import MyModule.myhandlandmark as ml
from fastapi import FastAPI
from fastapi.responses import StreamingResponse

app = FastAPI()

# ìµœì‹  í”„ë ˆì„ ì €ì¥ (ì›¹ ìŠ¤íŠ¸ë¦¬ë°ìš©)
latest_frame = None

# í”„ë ˆì„ì„ JPEGë¡œ ì¸ì½”ë”©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ë°˜í™˜
def encoding():
    while True:
        if latest_frame is not None:
            _, buffer = cv2.imencode('.jpg', latest_frame)
            yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')
            time.sleep(0.1)

# FastAPI ë¼ìš°íŠ¸: MJPEG ìŠ¤íŠ¸ë¦¬ë°
@app.get("/video")
def video_feed():
    return StreamingResponse(encoding(), media_type='multipart/x-mixed-replace; boundary=frame')

# FastAPI ì„œë²„ ì‹¤í–‰ (ì„œë¸ŒìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)
def start_fastapi(app):
    uvicorn.run(app, host="0.0.0.0", port=9001)

if __name__ == "__main__":

        # FastAPI ì‹¤í–‰ì„ ìœ„í•œ ì„œë¸ŒìŠ¤ë ˆë“œ ì‹œì‘
    inspection_thread = threading.Thread(target=start_fastapi, args=(app,), daemon=True)
    inspection_thread.start()

    # PLC í†µì‹  ì´ˆê¸°í™” (Type3E ë°©ì‹ ì‚¬ìš©, Q03UDEì™€ì˜ ì—°ê²°)
    pymc3e = mc.Type3E()
    pymc3e.connect("192.168.24.2", 8001)  # PLC IPì™€ í¬íŠ¸

    # ì† ì¶”ì ê¸° ì´ˆê¸°í™”
    hand = ml.handtracking()

    # ì¹´ë©”ë¼ ì—´ê¸° (1ë²ˆ ì¥ì¹˜)
    cap = cv2.VideoCapture(1)
    fps = cap.get(cv2.CAP_PROP_FPS)
    delay = int(1000 / fps)

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # í”„ë ˆì„ ì „ì²˜ë¦¬ ë° ì† ì¸ì‹
        img = hand.preprogress(frame)
        detection_result = hand.detector.detect(img)
        annotated_img, width, height = hand.draw_landmarks_on_image(img.numpy_view(), detection_result)
        hand_landmarks_list = detection_result.hand_landmarks

        # ROI í‘œì‹œ
        cv2.polylines(annotated_img, [hand.roi_polygon], isClosed=True, color=(255, 0, 0), thickness=2)
        
        # ì†ì´ ê°ì§€ë˜ì—ˆì„ ë•Œ
        if len(hand_landmarks_list) > 0: # ì†ì´ ê°ì§€ ë¬ì„ ë•Œ
            hand_points = []
            for i in range(21):
                hand_points.append(i) # Landmark index
            found_inside = False

            for point_idx in hand_points: # 
                pt = hand_landmarks_list[0][point_idx] # ê°ì§€ëœ ì†ì˜ Landmark ì¢Œí‘œ
                pt_x = int(pt.x * 640)
                pt_y = int(pt.y * 480)

                if hand.is_point_in_roi(pt_x, pt_y): # Landmark ì¢Œí‘œê°€ ROI ì•ˆì— ìˆëŠ”ì§€ í™•ì¸
                    found_inside = True
                    break

            if found_inside: # Landmark ì¢Œí‘œê°€ ROI ì•ˆì— ìˆì„ ë•Œ
                pymc3e.batchwrite_wordunits(headdevice="D8", values=[1]) # PLC D8ì— 1ì„ ì“´ë‹¤
                cv2.putText(annotated_img, "Warning : Hands detected. Emergence stop", 
                            (45, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)

        # ìµœì‹  í”„ë ˆì„ ì €ì¥ (ì›¹ ìŠ¤íŠ¸ë¦¬ë°ìš©)
        latest_frame = cv2.cvtColor(annotated_img, cv2.COLOR_RGB2BGR)

        # í™”ë©´ ì¶œë ¥
        cv2.imshow('CCTV', latest_frame)
       
        if cv2.waitKey(delay) & 0xFF == ord('q'):  # 'q' ëˆ„ë¥´ë©´ ì¢…ë£Œ
            break
        elif cv2.waitKey(delay) & 0xFF == ord('s'):
            cv2.imwrite('annotated_img.jpg', annotated_img)

    cap.release()
    cv2.destroyAllWindows()
